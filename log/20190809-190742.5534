Log file created at: 2019/08/09 19:07:42
Running on machine: leon-Inmotion
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0809 19:07:42.631233  5534 main.cpp:36] ---------- Init UART ----------
I0809 19:07:42.632416  5534 uart_configuration.cpp:57] had success load tabel
I0809 19:07:42.634945  5534 uart_configuration.cpp:210] fcntl=0
W0809 19:07:42.634994  5534 uart_configuration.cpp:216] standard input is not a terminal device
I0809 19:07:42.635366  5534 uart_configuration.cpp:225] fd->open=4
I0809 19:07:42.635458  5534 uart_configuration.cpp:67] Set port exactly!
I0809 19:07:42.635484  5534 uart_configuration.cpp:57] had success load tabel
I0809 19:07:42.635519  5534 uart_configuration.cpp:210] fcntl=0
W0809 19:07:42.635542  5534 uart_configuration.cpp:216] standard input is not a terminal device
I0809 19:07:42.635586  5534 uart_configuration.cpp:225] fd->open=6
I0809 19:07:42.635632  5534 uart_configuration.cpp:67] Set port exactly!
I0809 19:07:42.635687  5534 main.cpp:56] ---------- Start Get data through UART ----------
I0809 19:07:42.635816  5534 uart_configuration.cpp:43] uart_thread create success!
I0809 19:07:42.635846  5534 main.cpp:60] ---------- InitCamera ----------
I0809 19:07:43.791779  5895 uart_configuration.cpp:127] current Speed is:0
I0809 19:07:44.395794  5895 uart_configuration.cpp:127] current Speed is:0
I0809 19:07:44.437343  5534 main.cpp:68] ---------- START for Work ----------
I0809 19:07:44.437412  5534 uart_configuration.cpp:154] Roadway:OpenVoice!!!
I0809 19:07:44.599740  5895 uart_configuration.cpp:127] current Speed is:0
I0809 19:07:45.437554  5534 uart_configuration.cpp:160] Sideway:CloseVoice!!!
I0809 19:07:45.444339  5534 VideoImg.cpp:106] Start for saveVideo~
I0809 19:07:45.444412  5534 main.cpp:88] ---------- Start Prediction ----------
I0809 19:07:45.444542  5534 VideoImg.cpp:128] Classify_thread create success!
I0809 19:07:45.444643  6251 VideoImg.cpp:138] ---------- Loading model sysfile ----------
I0809 19:07:45.779721  5895 uart_configuration.cpp:127] current Speed is:0
I0809 19:07:47.367712  5895 uart_configuration.cpp:127] current Speed is:0
I0809 19:07:47.571708  5895 uart_configuration.cpp:127] current Speed is:0
I0809 19:07:47.780988  5895 uart_configuration.cpp:127] current Speed is:0
I0809 19:07:47.983744  5895 uart_configuration.cpp:127] current Speed is:0
I0809 19:07:48.203322  6251 net.cpp:53] Initializing net from parameters: 
name: "Resnet18"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1/bn"
  top: "conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1/bn"
  top: "conv1/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2.1.conv1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2.1.conv1"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res2.1.conv1/bn"
  type: "BatchNorm"
  bottom: "res2.1.conv1"
  top: "res2.1.conv1/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res2.1.conv1/scale"
  type: "Scale"
  bottom: "res2.1.conv1/bn"
  top: "res2.1.conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2.1.conv1/relu"
  type: "ReLU"
  bottom: "res2.1.conv1/bn"
  top: "res2.1.conv1/bn"
}
layer {
  name: "res2.1.conv2"
  type: "Convolution"
  bottom: "res2.1.conv1/bn"
  top: "res2.1.conv2"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res2.1.conv2/bn"
  type: "BatchNorm"
  bottom: "res2.1.conv2"
  top: "res2.1.conv2/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res2.1.conv2/scale"
  type: "Scale"
  bottom: "res2.1.conv2/bn"
  top: "res2.1.conv2/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2.1.sum"
  type: "Eltwise"
  bottom: "res2.1.conv2/bn"
  bottom: "pool1"
  top: "res2.1.sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res2.1.relu"
  type: "ReLU"
  bottom: "res2.1.sum"
  top: "res2.1.sum"
}
layer {
  name: "res2.2.conv1"
  type: "Convolution"
  bottom: "res2.1.sum"
  top: "res2.2.conv1"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res2.2.conv1/bn"
  type: "BatchNorm"
  bottom: "res2.2.conv1"
  top: "res2.2.conv1/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res2.2.conv1/scale"
  type: "Scale"
  bottom: "res2.2.conv1/bn"
  top: "res2.2.conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2.2.conv1/relu"
  type: "ReLU"
  bottom: "res2.2.conv1/bn"
  top: "res2.2.conv1/bn"
}
layer {
  name: "res2.2.conv2"
  type: "Convolution"
  bottom: "res2.2.conv1/bn"
  top: "res2.2.conv2"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res2.2.conv2/bn"
  type: "BatchNorm"
  bottom: "res2.2.conv2"
  top: "res2.2.conv2/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res2.2.conv2/scale"
  type: "Scale"
  bottom: "res2.2.conv2/bn"
  top: "res2.2.conv2/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2.2.sum"
  type: "Eltwise"
  bottom: "res2.2.conv2/bn"
  bottom: "res2.1.sum"
  top: "res2.2.sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res2.2.relu"
  type: "ReLU"
  bottom: "res2.2.sum"
  top: "res2.2.sum"
}
layer {
  name: "res3.1.conv1"
  type: "Convolution"
  bottom: "res2.2.sum"
  top: "res3.1.conv1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res3.1.conv1/bn"
  type: "BatchNorm"
  bottom: "res3.1.conv1"
  top: "res3.1.conv1/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res3.1.conv1/scale"
  type: "Scale"
  bottom: "res3.1.conv1/bn"
  top: "res3.1.conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3.1.conv1/relu"
  type: "ReLU"
  bottom: "res3.1.conv1/bn"
  top: "res3.1.conv1/bn"
}
layer {
  name: "res3.1.conv2"
  type: "Convolution"
  bottom: "res3.1.conv1/bn"
  top: "res3.1.conv2"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res3.1.conv2/bn"
  type: "BatchNorm"
  bottom: "res3.1.conv2"
  top: "res3.1.conv2/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res3.1.conv2/scale"
  type: "Scale"
  bottom: "res3.1.conv2/bn"
  top: "res3.1.conv2/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3.1.skipConv"
  type: "Convolution"
  bottom: "res2.2.sum"
  top: "res3.1.skipConv"
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res3.1.skipConv/bn"
  type: "BatchNorm"
  bottom: "res3.1.skipConv"
  top: "res3.1.skipConv/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res3.1.skipConv/scale"
  type: "Scale"
  bottom: "res3.1.skipConv/bn"
  top: "res3.1.skipConv/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3.1.sum"
  type: "Eltwise"
  bottom: "res3.1.conv2/bn"
  bottom: "res3.1.skipConv/bn"
  top: "res3.1.sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res3.1.relu"
  type: "ReLU"
  bottom: "res3.1.sum"
  top: "res3.1.sum"
}
layer {
  name: "res3.2.conv1"
  type: "Convolution"
  bottom: "res3.1.sum"
  top: "res3.2.conv1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res3.2.conv1/bn"
  type: "BatchNorm"
  bottom: "res3.2.conv1"
  top: "res3.2.conv1/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res3.2.conv1/scale"
  type: "Scale"
  bottom: "res3.2.conv1/bn"
  top: "res3.2.conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3.2.conv1/relu"
  type: "ReLU"
  bottom: "res3.2.conv1/bn"
  top: "res3.2.conv1/bn"
}
layer {
  name: "res3.2.conv2"
  type: "Convolution"
  bottom: "res3.2.conv1/bn"
  top: "res3.2.conv2"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res3.2.conv2/bn"
  type: "BatchNorm"
  bottom: "res3.2.conv2"
  top: "res3.2.conv2/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res3.2.conv2/scale"
  type: "Scale"
  bottom: "res3.2.conv2/bn"
  top: "res3.2.conv2/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3.2.sum"
  type: "Eltwise"
  bottom: "res3.2.conv2/bn"
  bottom: "res3.1.sum"
  top: "res3.2.sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res3.2.relu"
  type: "ReLU"
  bottom: "res3.2.sum"
  top: "res3.2.sum"
}
layer {
  name: "res4.1.conv1"
  type: "Convolution"
  bottom: "res3.2.sum"
  top: "res4.1.conv1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res4.1.conv1/bn"
  type: "BatchNorm"
  bottom: "res4.1.conv1"
  top: "res4.1.conv1/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res4.1.conv1/scale"
  type: "Scale"
  bottom: "res4.1.conv1/bn"
  top: "res4.1.conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4.1.conv1/relu"
  type: "ReLU"
  bottom: "res4.1.conv1/bn"
  top: "res4.1.conv1/bn"
}
layer {
  name: "res4.1.conv2"
  type: "Convolution"
  bottom: "res4.1.conv1/bn"
  top: "res4.1.conv2"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res4.1.conv2/bn"
  type: "BatchNorm"
  bottom: "res4.1.conv2"
  top: "res4.1.conv2/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res4.1.conv2/scale"
  type: "Scale"
  bottom: "res4.1.conv2/bn"
  top: "res4.1.conv2/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4.1.skipConv"
  type: "Convolution"
  bottom: "res3.2.sum"
  top: "res4.1.skipConv"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res4.1.skipConv/bn"
  type: "BatchNorm"
  bottom: "res4.1.skipConv"
  top: "res4.1.skipConv/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res4.1.skipConv/scale"
  type: "Scale"
  bottom: "res4.1.skipConv/bn"
  top: "res4.1.skipConv/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4.1.sum"
  type: "Eltwise"
  bottom: "res4.1.conv2/bn"
  bottom: "res4.1.skipConv/bn"
  top: "res4.1.sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res4.1.relu"
  type: "ReLU"
  bottom: "res4.1.sum"
  top: "res4.1.sum"
}
layer {
  name: "res4.2.conv1"
  type: "Convolution"
  bottom: "res4.1.sum"
  top: "res4.2.conv1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res4.2.conv1/bn"
  type: "BatchNorm"
  bottom: "res4.2.conv1"
  top: "res4.2.conv1/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res4.2.conv1/scale"
  type: "Scale"
  bottom: "res4.2.conv1/bn"
  top: "res4.2.conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4.2.conv1/relu"
  type: "ReLU"
  bottom: "res4.2.conv1/bn"
  top: "res4.2.conv1/bn"
}
layer {
  name: "res4.2.conv2"
  type: "Convolution"
  bottom: "res4.2.conv1/bn"
  top: "res4.2.conv2"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res4.2.conv2/bn"
  type: "BatchNorm"
  bottom: "res4.2.conv2"
  top: "res4.2.conv2/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res4.2.conv2/scale"
  type: "Scale"
  bottom: "res4.2.conv2/bn"
  top: "res4.2.conv2/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4.2.sum"
  type: "Eltwise"
  bottom: "res4.2.conv2/bn"
  bottom: "res4.1.sum"
  top: "res4.2.sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res4.2.relu"
  type: "ReLU"
  bottom: "res4.2.sum"
  top: "res4.2.sum"
}
layer {
  name: "res5.1.conv1"
  type: "Convolution"
  bottom: "res4.2.sum"
  top: "res5.1.conv1"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res5.1.conv1/bn"
  type: "BatchNorm"
  bottom: "res5.1.conv1"
  top: "res5.1.conv1/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res5.1.conv1/scale"
  type: "Scale"
  bottom: "res5.1.conv1/bn"
  top: "res5.1.conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5.1.conv1/relu"
  type: "ReLU"
  bottom: "res5.1.conv1/bn"
  top: "res5.1.conv1/bn"
}
layer {
  name: "res5.1.conv2"
  type: "Convolution"
  bottom: "res5.1.conv1/bn"
  top: "res5.1.conv2"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res5.1.conv2/bn"
  type: "BatchNorm"
  bottom: "res5.1.conv2"
  top: "res5.1.conv2/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res5.1.conv2/scale"
  type: "Scale"
  bottom: "res5.1.conv2/bn"
  top: "res5.1.conv2/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5.1.skipConv"
  type: "Convolution"
  bottom: "res4.2.sum"
  top: "res5.1.skipConv"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res5.1.skipConv/bn"
  type: "BatchNorm"
  bottom: "res5.1.skipConv"
  top: "res5.1.skipConv/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res5.1.skipConv/scale"
  type: "Scale"
  bottom: "res5.1.skipConv/bn"
  top: "res5.1.skipConv/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5.1.sum"
  type: "Eltwise"
  bottom: "res5.1.conv2/bn"
  bottom: "res5.1.skipConv/bn"
  top: "res5.1.sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res5.1.relu"
  type: "ReLU"
  bottom: "res5.1.sum"
  top: "res5.1.sum"
}
layer {
  name: "res5.2.conv1"
  type: "Convolution"
  bottom: "res5.1.sum"
  top: "res5.2.conv1"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res5.2.conv1/bn"
  type: "BatchNorm"
  bottom: "res5.2.conv1"
  top: "res5.2.conv1/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res5.2.conv1/scale"
  type: "Scale"
  bottom: "res5.2.conv1/bn"
  top: "res5.2.conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5.2.conv1/relu"
  type: "ReLU"
  bottom: "res5.2.conv1/bn"
  top: "res5.2.conv1/bn"
}
layer {
  name: "res5.2.conv2"
  type: "Convolution"
  bottom: "res5.2.conv1/bn"
  top: "res5.2.conv2"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "res5.2.conv2/bn"
  type: "BatchNorm"
  bottom: "res5.2.conv2"
  top: "res5.2.conv2/bn"
  batch_norm_param {
    moving_average_fraction: 0.9
    eps: 0.0001
  }
}
layer {
  name: "res5.2.conv2/scale"
  type: "Scale"
  bottom: "res5.2.conv2/bn"
  top: "res5.2.conv2/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5.2.sum"
  type: "Eltwise"
  bottom: "res5.2.conv2/bn"
  bottom: "res5.1.sum"
  top: "res5.2.sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res5.2.relu"
  type: "ReLU"
  bottom: "res5.2.sum"
  top: "res5.2.sum"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res5.2.sum"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 4
  }
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "pool2"
  top: "fc"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc"
  top: "prob"
}
I0809 19:07:48.207437  6251 layer_factory.hpp:77] Creating layer data
I0809 19:07:48.207603  6251 net.cpp:86] Creating Layer data
I0809 19:07:48.207859  6251 net.cpp:382] data -> data
I0809 19:07:48.453356  6251 net.cpp:124] Setting up data
I0809 19:07:48.453449  6251 net.cpp:131] Top shape: 1 3 112 112 (37632)
I0809 19:07:48.453510  6251 net.cpp:139] Memory required for data: 150528
I0809 19:07:48.453557  6251 layer_factory.hpp:77] Creating layer conv1
I0809 19:07:48.453626  6251 net.cpp:86] Creating Layer conv1
I0809 19:07:48.453667  6251 net.cpp:408] conv1 <- data
I0809 19:07:48.453722  6251 net.cpp:382] conv1 -> conv1
I0809 19:07:49.352071  5895 uart_configuration.cpp:127] current Speed is:0
I0809 19:07:49.555963  5895 uart_configuration.cpp:127] current Speed is:0
I0809 19:07:50.545514  5895 uart_configuration.cpp:127] current Speed is:0
I0809 19:07:50.939759  5895 uart_configuration.cp